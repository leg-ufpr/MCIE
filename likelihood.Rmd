# Verossimilhança

Neste Capítulo apresentamos conceitos fundamentais de inferência estatística
com ênfase aos relacionados à função de verossimilhança.

```{definition}
**Função de verossimilhança** - Seja $\mathbf{y}$ um vetor $n \times 1$ representando uma realização de um vetor aleatório $\mathbf{Y}$ com função de probabilidade ou densidade probabilidade $\mathrm{f}(\mathbf{Y},\boldsymbol{\theta})$, onde $\boldsymbol{\theta}$ denota um vetor $p \times 1$ de parâmetros, com $\boldsymbol{\theta} \in \Theta$, sendo $\Theta$ o respectivo espaço paramétrico. 
A função de verossimilhança ou simplesmente verossimilhança para $\boldsymbol{\theta}$ dado os valores observados $\mathbf{y}$ 
é a função $\mathrm{L}(\boldsymbol{\theta}| \mathbf{y}) \equiv \mathrm{f}(\mathbf{Y},\boldsymbol{\theta})$. 

```

A função de verossimilhança é dada pela expressão da distribuição conjunta de todas as variáveis aleatórias envolvidas no modelo, porém vista como função dos parâmetros, uma vez que tendo os dados sido observados, são quantidades fixas. Para cada particular valor do parâmetro que pode ser escalar ou vetor, 
a verossimilhança é uma medida de compatibilidade, plausibilidade ou similaridade do modelo com a amostra observada medida pela probabilidade ou densidade conjunta dos valores observados. Fracamente falando, pode-se
dizer que a verossimilhança nos fornece a probabilidade de observar o que
foi realmente observado, dado o modelo assumido para os dados.

A expressão da verossimilhança $\mathrm{L}(\boldsymbol{\theta}| \mathbf{y})$ 
pode ser mais cuidadosamente definida considerando a natureza das variáveis aleatórias.
Para modelos discretos não há ambiguidade e o valor da função de verossimilhança é a probabilidade de ocorrer o dado observado, ou seja
\[
\mathrm{L}(\boldsymbol{\theta}|\mathbf{y}) \equiv \mathrm{P}_{\boldsymbol{\theta}}(\mathbf{Y}=\mathbf{y}). \]
No caso de modelos contínuos a probabilidade de um particular conjunto de 
valores ser observado é nula. Entretanto, na prática medidas contínuas são tomadas com algum grau de precisão em um intervalo, digamos,
$y_{iI} \leq y_i \leq y_{iS}$ e a verossimilhança para um conjunto de observações é:
\begin{equation}\label{eq:verogeral}
\mathrm{L}(\boldsymbol{\theta}|\mathbf{y}) = \mathrm{P}_{\boldsymbol{\theta}}(y_{1I} \leq y_1 \leq y_{1S}, y_{2I} \leq y_2 \leq y_{2S}, 
\ldots, y_{nI} \leq y_n \leq y_{nS}).
\end{equation}
Esta definição é geral e requer a especificação da distribuição conjunta
de $\mathrm{Y}$. Fazendo a suposição de observações independentes tem-se que:
\begin{equation}\label{eq:veroind}
\mathrm{L}(\boldsymbol{\theta}|\mathbf{y}) = \mathrm{P}_{\boldsymbol{\theta} }(y_{1I} \leq y_1 \leq y_{1S}) \cdot \mathrm{P}_{\boldsymbol{\theta}}(y_{2I} \leq y_2 \leq y_{2S}), \ldots ,
\mathrm{P}_{\boldsymbol{\theta}}(y_{nI} \leq y_n \leq y_{nS}).
\end{equation}
Até este ponto a definição pode ser utilizada tanto para dados considerados
pontuais quanto para  dados intervalares, como no caso de dados censurados.
Vamos supor agora uma situação mais simples e comum na qual todos os dados
são medidos a um grau de precisão comum.
Neste caso, cada dado é medido em um intervalo 
$(y_i - \delta/2 \leq Y_i \leq y_i + \delta/2)$
e a verossimilhança é dada por:
\begin{align*}
\mathrm{L}(\boldsymbol{\theta}|\mathbf{y}) &= \prod_{i=1}^n \mathrm{P}_{\boldsymbol{\theta} }(y_i - \delta/2 \leq Y_i \leq y_i + \delta/2) \\
&= \prod_{i=1}^n \int_{y_i - \delta/2}^{y_i + \delta/2} \mathrm{f}(y_i , \boldsymbol{\theta}) \mathrm{d}y_i.
\end{align*}
Se o grau de precisão é alto, ou seja $\delta$ é pequeno em relação a variabilidade dos dados a expressão se reduz a
\[ \mathrm{L}(\boldsymbol{\theta}|\mathbf{y}) \approx \left(\prod_{i=1}^n \mathrm{f}(y_i, \boldsymbol{\theta}) \right) \delta^n  , \]
e se $\delta$ não depende dos valores dos parâmetros temos a verossimilhança
como produto das densidades individuais,  
\begin{equation}\label{eq:veroiid}
\mathrm{L}(\boldsymbol{\theta}|\mathbf{y}) \approx \prod_{i=1}^n \mathrm{f}(y_i, \boldsymbol{\theta})  ,
\end{equation}
e de forma mais geral para observações não independentes 
com a densidade multivariada: 
\begin{equation}\label{eq:veromv}
\mathrm{L}(\boldsymbol{\theta}|\mathbf{y}) \approx \mathrm{f}(\mathbf{y}, \boldsymbol{\theta}) .
\end{equation}

No caso onde os elementos de $\mathbf{y}$ são independentes a verossimilhança é simplesmente um produto das distribuições de cada variável aleatória $Y_i$ individualmente, ou seja, $\mathrm{L}(\boldsymbol{\theta}| \mathbf{y}) = \prod_{i=1}^n \mathrm{f}(y_i, \boldsymbol{\theta})$. 
Neste caso, o procedimento de inferência pode ser bastante facilitado tanto analítica como computacionalmente. Porém, cabe ressaltar que isso não é uma exigência, e situações onde as amostras não são independentes são tratadas da mesma forma, escrevendo a verossimilhança de uma forma adequada, 
considerando a distribuição conjunta do vetor $\mathbf{Y}$. 

Esta parte do texto concentra-se exclusivamente no uso da função de verossimilhança como base para explicar os aspectos envolvidos na inferência estatística, seja na obtenção de estimativas pontuais, intervalares ou testes de hipótese. Começamos revisando conceitos de estimação e suas relações com a função de verossimilhança.

## Estimação pontual

Seja $Y_1, Y_2, \ldots, Y_n$ variáveis aleatórias com forma conhecida da
função probabilidade no caso de variáveis aleatórias discretas ou 
da função densidade de probabilidade para variáveis aleatórias contínuas, em ambos os casos denotadas por $\mathrm{f}(\mathbf{Y}, \boldsymbol{\theta})$. 
O vetor $\boldsymbol{\theta}$ denota os parâmetros desconhecidos, sendo que um único elemento de $\boldsymbol{\theta}$ será denotado por $\theta$, o qual queremos estimar através de uma 
amostra $y_1, y_2, \ldots, y_n$, de realizações das variáveis aleatórias $Y_1, Y_2, \ldots, Y_n$. Denota-se de forma simplificada, $Y_i \sim \mathrm{f}(\boldsymbol{\theta})$ com $i = 1, \ldots, n$. Esta notação deve ser lida da seguinte forma: a variável aleatória $Y_i$ segue uma distribuição $\mathrm{f(\cdot)}$ que por sua vez é indexada, descrita ou governada por um vetor de parâmetros $\boldsymbol{\theta}$. A seguir apresentamos algumas definições importantes para o decorrer do texto.

```{definition}
**Estatística** - Uma estatística é uma variável aleatória $\mathrm{T} = \mathrm{t}(\mathbf{Y})$, onde a função $\mathrm{t}(\cdot)$ não depende de $\boldsymbol{\theta}$.

```

```{definition}
**Estimador** - Uma estatística $\mathrm{T}$ é um estimador para $\theta$ se o valor realizado $\mathrm{t} = \mathrm{t}(\boldsymbol{y})$ é usado como uma estimativa para o valor de $\theta$.

```

```{definition}
**Distribuição amostral** - A distribuição de probabilidade de $\mathrm{T}$ é chamada de distribuição amostral do estimador $\mathrm{t}(\mathbf{Y})$.

```

```{definition}
**Viés** - O viés de um estimador $\mathrm{T}$ é a quantidade $$\mathrm{B}(\mathrm{T}) = \mathrm{E}(\mathrm{T} - \theta).$$ O estimador $\mathrm{T}$ é dito não viciado para $\theta$ se $\mathrm{B}(\mathrm{T}) = 0$, tal que $\mathrm{E}(\mathrm{T}) = \theta$. O estimador $\mathrm{T}$ é assintoticamente não viciado para $\theta$ se $\mathrm{E}(\mathrm{T}) \to \theta$ quando $n \to \infty$.

```

```{definition}
**Eficiência relativa** - A eficiência relativa entre dois estimadores $\mathrm{T_1}$ e $\mathrm{T_2}$ é a razão $\mathrm{er} = \frac{\mathrm{V}(\mathrm{T_1})}{\mathrm{V}(\mathrm{T_2})}$ em que $\mathrm{V}(\cdot)$ denota a variância do respectivo estimador.

```

```{definition}
**Erro quadrático médio** - O erro quadrático médio de um estimador $\mathrm{T}$ é a quantidade \[ \mathrm{EQM}(\mathrm{T}) = \mathrm{E}( ( \mathrm{T} - \theta)^2 ) = \mathrm{V}(\mathrm{T}) + \mathrm{B}(\mathrm{T})^2 . \]

```

```{definition}
**Consistência** - Um estimador $\mathrm{T}$ é **médio quadrático consistente** para $\theta$ se o $\mathrm{EQM}(\mathrm{T}) \to 0$ quando $n \to \infty$. O estimador $\mathrm{T}$ é **consistente em probabilidade** se $\forall \epsilon > 0$, $\mathrm{P}( | \mathrm{T} - \theta | > \epsilon) \to 0$, quando $n \to \infty$.

```

Estas definições introduzem conceitos e propriedades básicas para uma estatística ser um estimador adequado para um determinado parâmetro. Fracamente falando, o desejo é obter um estimador que seja assintóticamente não-viciado, ou seja, conforme o tamanho da amostra aumenta ele se aproxima cada vez mais do verdadeiro valor do parâmetro. Além disso, é interessante que ele seja eficiente, ou seja, apresente a menor variância possível entre todos os estimadores de $\theta$. Esta definição de eficiência, introduz o conceito de variância minima. Sendo assim, para saber se um estimador é eficiente é necessário conhecer um limite inferior para a variância de um estimador, uma vez que tal quantidade exista e seja passível de calcular, ao propor um estimador para $\theta$, basta calcular a sua variância e comparar com a menor possível, se ele atingir este limite será eficiente. Além disso, tomando sua esperança pode-se concluir sobre o seu viés dependendo da situação em termos assintóticos. O Teorema \@ref(thm:cramer), ajuda a responder sobre a eficiência de um estimador qualquer. Mas antes precisamos de mais algumas definições.

Como dito, a verossimilhança é uma medida de compatibilidade da amostra observada com um particular vetor de parâmetros, desta forma é natural definir como estimador para o vetor de parâmetros $\boldsymbol{\theta}$, aquele particular vetor digamos, $\hat{\boldsymbol{\theta}}$, que tenha a maior compatibilidade com a amostra, ou em outras palavras o vetor que maximiza a função de verossimilhança ou compatibilidade.
O particular valor assumido pela função de verossimilhança neste caso não é importante, 
o que interessa para **inferência** são os valores relativos de 
$\mathrm{L}(\boldsymbol{\theta}|\mathrm{y})$ para diferentes conjuntos de $\boldsymbol{\theta}$. 

```{definition}
**Estimativa de máxima verossimilhança** - 
  Seja $\mathrm{L}(\boldsymbol{\theta}|\mathbf{y})$ a função de verossimilhança. 
O valor $\hat{\boldsymbol{\theta}} = \hat{\boldsymbol{\theta}}(\mathbf{y})$ é a estimativa de máxima verossimilhança para $\boldsymbol{\theta}$ se $\mathrm{L}(\hat{\boldsymbol{\theta}}) \ge \mathrm{L}(\boldsymbol{\theta})$, $\forall \boldsymbol{\theta} \in \Theta$.

```

```{definition}
**Estimador de máxima verossimilhança** - Se $\hat{\boldsymbol{\theta}}(\mathbf{y})$ é a estimativa de máxima verossimilhança, então $\hat{\boldsymbol{\theta}}(\mathbf{Y})$ é o estimador de máxima verossimilhança. Em geral vamos usar a abreviação EMV para nos referirmos ao estimador de máxima verossimilhança.

```

Nesta etapa é preciso ter cuidado com a notação. Veja que $\hat{\boldsymbol{\theta}}(\mathbf{y})$ é um vetor de escalares, por outro lado $\hat{\boldsymbol{\theta}}(\mathbf{Y})$ é um vetor de variáveis aleatórias. Daqui em diante usaremos apenas $\hat{\boldsymbol{\theta}}$, para ambos os casos sendo que o contexto indicará o real sentido de $\hat{\boldsymbol{\theta}}$. A função de verossimilhança contêm toda a informação proveniente dos dados sobre o vetor de parâmetros $\boldsymbol{\theta}$. Apesar disso, a $\mathrm{L}(\boldsymbol{\theta}|\mathbf{y})$ é computacionalmente incoveniente, uma vez que esta função apresentará valores muito próximos de zero, conforme o tamanho da amostra aumenta. Por razões meramente computacionais é mais comum usar a função de log-verossimilhança.

```{definition}
**Log-verossimilhança** - Se $\mathrm{L}(\boldsymbol{\theta}|\mathbf{y})$ é a função de verossimilhança, então $\mathrm{l}(\boldsymbol{\theta}|\mathbf{y}) = \log \mathrm{L}(\boldsymbol{\theta}|\mathbf{y})$ é a função de log-verossimilhança.

```

Segue do fato da função logaritmo ser monótona crescente que maximizar $\mathrm{L}(\boldsymbol{\theta}|\mathbf{y})$ e $\mathrm{l}(\boldsymbol{\theta}|\mathbf{y})$ 
levam ao mesmo ponto de máximo. Neste ponto estamos habilitados a enunciar um dos teoremas mais fortes da inferência estatística que permitirá concluir sobre a eficiência de um estimador. Neste texto vamos enunciar o Teorema apenas para um o caso em que
$\theta$ é um escalar, porém o caso multiparâmetros segue de forma analoga.


```{theorem, label="cramer"}
**Limite inferior de Cramer-Rao** - Se $\mathrm{T}$ é um estimador não-viciado para $\theta$ e $\mathrm{l}(\theta|\mathbf{Y})$ é duas vezes diferenciável com respeito a $\theta$, então
\[ \mathrm{V}(\mathrm{T}) \ge \frac{1}{\mathrm{E}( - \mathrm{l}^{\prime \prime}(\theta| \mathbf{Y}) )} . \]

```

Este teorema informa o limite inferior para a variância de um estimador $\hat{T}$ qualquer. O estimador de máxima verossimilhança apresenta propriedades ótimas e uma delas é a eficiência, ou seja, assintóticamente o EMV atinge o limite inferior de Cramer-Rao. Antes de discutirmos as propriedades dos estimadores de máxima verossimilhança, vamos apresentar uma forma de introduzir a incerteza associada a estimativa de um parâmetro qualquer. Lembre-se que o estimador é um variável aleatória, a estimativa é uma realização desta variável aleatória. Sendo assim, quando reportamos apenas a estimativa pontual, estamos ignorando a incerteza associada a esta estimativa. Uma forma, tradicional de se medir e informar a incerteza associada é com a construção de intervalos de confiança.

```{example, label="ex1"}
**Estimação pontual: Distribuição Poisson** - 
```  

Neste exemplo vamos considerar um problema para o qual o estimador de máxima verossimilhança pode ser obtido analiticamente, porém vamos explorar diversas formas de obtê-lo também numéricamente utilizando ferramentas disponíveis em **R**. 
Vamos começar mostrando quatro representações da função de verossimilhança.

O modelo que vamos considerar é o modelo Poisson. Sendo assim, seja $Y_i \sim P(\lambda)$ com $i = 1, \ldots, n$, variáveis aleatórias independentes e denote $\overline{y} = \sum_{i=1}^n y_i/n$. A função de verossimilhança é o produto das $n$ distribuições de Poisson com parâmetro $\lambda$ que neste caso é assumido comum a todas as variáveis aleatórias e desconhecido. A função de verossimilhança é dada pela expressão a seguir, notando-se que, observada uma determinada amostra, o termo no denominador é uma constante.

$$
\mathrm{L}(\lambda) = \prod_{i=1}^n \frac{\exp\{-\lambda\} \lambda^{y_i}}{y_i!} = 
                \frac{\exp\{-n \lambda\} \lambda^{\sum_{i=1}^n y_i}}{\prod_{i=1}^n y_i !}.
$$
  
Um representação alternativa é a função de verossimilhança relativa. 
Sendo, $\hat{\lambda}$ o EMV para $\lambda$ a função de verossimilhança relativa é dada por $\mathrm{LR}(\lambda) = \frac{\mathrm{L}(\lambda)}{\mathrm{L}(\hat{\lambda})}$ que para esse exemplo, após uma série de simplificações, tem a seguinte expressão
$$
\mathrm{LR}(\lambda) = \exp\{-n(\lambda-\hat{\lambda})\} (\lambda/\hat{\lambda})^{n \overline{y}}.
$$

A verossimilhança relativa assume sempre valores no intervalo unitário o que facilita a construção e visualização de gráficos. Note ainda que nesta representação o termo constante no denominador é cancelado. Além disso, uma vez que o termo constante envolve o cálculo de fatoriais o fato do termo cancelar é muito conveniente computationalmente, uma vez que o cálculo de fatoriais é altamente suceptível a problemas numéricos.

Outra possibilidade é usar a função de log-verossimilhança $\mathrm{l}(\lambda) = \log \mathrm{L}(\lambda)$ que normalmente é preferida para se trabalhar analítica e computacionalmente. Para o exemplo da distribuição de Poisson, a expressão é como se segue
com o último termo constante para uma determinada amostra.
$$
\mathrm{l}(\lambda) = - n \lambda + n \overline{y} \log(\lambda) - \sum_{i=1}^n \log(y_i!).
$$

Por fim, podemos ainda utilizar a função _deviance_ dada por, 
$\mathrm{D}(\lambda) = -2 \mathrm{LR}(\lambda) = 2\{ \mathrm{l}(\hat{\lambda}) - \mathrm{l}(\lambda) \}$, 
que é comumente reportada por algoritmos e utilizada na obtenção de intervalos de confiança e testes de hipóteses devido as suas propriedades assintóticas, conforme será discutida nas próximas seções. Assim como na verossimilhança relativa, a sua expressão elimina o termo constante ficando na forma:
$$
\mathrm{D}(\lambda) = 2 n \{(\hat{\lambda}-\lambda)-\overline{y} \log(\hat{\lambda}/\lambda)\}.
$$

Neste caso o estimador de máxima verossimilhança para $\lambda$ pode ser encontrado analiticamente maximizando a função de log-verossimilhança. O primeiro passo é encontrar a verossimilhança e a log-verossimilhança.

\begin{align*}
\mathrm{L}(\lambda) &= \prod_{i=1}^n \frac{ \exp\{-\lambda\} \lambda^{y_i}}{y_i !} = \frac{ \exp\{-n \lambda\} 
\lambda^{\sum_{i=1}^n y_i}}{\prod_{i=1}^n y_i !} \\
\mathrm{l}(\lambda) &= - n \lambda + (\sum_{i=1}^n y_i) \log (\lambda) - \sum_{i=1}^n \log y_i ! \\
\end{align*}

Para encontrar o ponto de máximo da log-verossimilhança, vamos usar a estratégia padrão de cálculo diferencial que consiste em encontrar a primeira derivada, usando a nossa terminologia vamos obter a função escore.

\begin{align*}
\mathrm{U}(\lambda) &= - n + \frac{\sum_{i=1}^n y_i}{\lambda}  \\
\end{align*}

Resolvendo a equação, temos
\begin{align*}
\mathrm{U}(\hat{\lambda}) &= - n + \frac{\sum_{i=1}^n y_i}{\hat{\lambda}} = 0  \\
\hat{\lambda} &= \frac{\sum_{i=1}^n y_i}{n} = \overline{y}. 
\end{align*}

Por fim, podemos também obter a segunda derivada e verificar se ela é negativa para confirmar que o ponto encontrado é realmente um ponto de máximo.

\begin{align*}
\mathrm{H}(\lambda) =  -\frac{ \sum_{i=1}^n y_i}{ \lambda^2}.
\end{align*}

Dado que $y_i$ e $\lambda$ são estritamente positivo a segunda derivada
$\mathrm{H}(\lambda)$ é negativa, mostrando que o ponto obtido é de máximo.

Para ilustrar graficamente as diferentes representações da verossimilhança vamos simular uma amostra da distribuição de Poisson com parâmetro $\lambda = 10$.
Note que vamos fixar a semente usando a função `set.seed()` para que os
resultados sejam reproduzíveis.

```{r}
set.seed(20)
y <- rpois(20, lambda=10)
```

A Figura \@ref(fig:veroExemplo1), apresenta os gráficos dessas quatro formas de visualização da função de verossimilhança para os dados simulados. 
Utilizamos a função definida no código \@ref(lem:verosPois) que permite
escolher a representação desejada da verossimilhança. As verossimilhanças relativa e _deviance_ requerem que o valor da verossimilhança maximizada seja informado no argumento 
`maxlogL`, que é constante para uma determinada amostra. Deixamos este cálculo fora da função para evitar que esta quantidade constante seja recalculado nas sucessivas avaliações da função. Para facilitar o obtenção dos gráficos definimos a função na forma vetorizada utilizando `sapply()`. Assim, a função pode receber um vetor de valores do parâmetro.

```{lemma, verosPois}
**Função com diferentes representações da verossimilhança - Distribuição Poisson.**
```

```{r echo = TRUE}
veroPois <- function(par, dados, tipo, maxlogL){
   tipo = match.arg(tipo, choices=c("L","LR","logL","dev"))
   ll <- sapply(par, function(p) sum(dpois(dados, lambda=p, log=TRUE)))
   return(switch(tipo, "L" = exp(ll),
                       "LR" = exp(ll-maxlogL),
                       "logL" = ll,
                       "dev" = 2*(maxlogL-ll)))} 
```

Os comandos a seguir mostram a obtenção da log-verossimilhança maximizada $\mathrm{l}(\hat{\lambda})$ e a chamada para obter o gráfico da função _deviance_ $\mathrm{D}(\lambda)$. Para os demais gráficos basta alterar os valores do 
argumento `tipo.` 

```{r echo = TRUE, eval = FALSE}
mll <- sum(dpois(y, lambda = mean(y), log = TRUE))
curve(veroPois(x, dados = y, tipo = "dev", maxlogL = mll), 8, 11, 
      ylab=expression(D(lambda)), xlab=expression(lambda))
```

```{r veroExemplo1, echo = FALSE, fig.width = 8, fig.height = 2, fig.cap = 'Diferentes formas de visualizar a função de verossimilhança - Distribuição Poisson.'}
par(mfrow = c(1, 4), mar=c(2.6, 2.6, 1.2, 0.5), mgp = c(1.6, 0.6, 0))
mll <- sum(dpois(y, lambda=mean(y), log=TRUE))
curve(veroPois(x, dados=y, tipo="L", maxlogL=mll), 8, 11, 
      ylab=expression(L(lambda)), xlab=expression(lambda))
curve(veroPois(x, dados=y, tipo="LR", maxlogL=mll), 8, 11,
      ylab=expression(LR(lambda)),xlab=expression(lambda))
curve(veroPois(x, dados=y, tipo="logL", maxlogL=mll), 8, 11,
      ylab=expression(l(lambda)),xlab=expression(lambda))
curve(veroPois(x, dados=y, tipo="dev", maxlogL=mll), 8, 11,
      ylab=expression(D(lambda)),xlab=expression(lambda))

```

Apesar das quatro formas serem equivalentes a forma usual para encontrar o estimador de máxima verossimilhança é a log-verossimilhança. De forma geral, cálculos analíticos com a função de verossimilhança $\mathrm{L}(\lambda)$ podem ser mais trabalhosos enquanto que sua computação mais sensível a valores que podem gerar problemas numéricos, por exemplo excedendo a capacidade de representação de números. A verosimilhança relativa e a _deviance_ requerem o valor da função de verosimilhança avaliado na estimativa.

Embora neste exemplo o EMV pode ser encontrado analiticamente, vamos ilustrar a sua obtenção usando métodos numéricos comumente utilizados para encontrar EMV em situações mais desafiadoras. Mas antes disto vamos redefinir a função de verossimilhança
escrita agora como função da estatística suficiente calculada com os valores da amostra.
Definimos $\mathrm{l}(\lambda)$ como opção _default_. O argumento `amostra` deve receber uma lista com o tamanho e a soma dos termos da amostra. Omitimos em $\mathrm{L}(\lambda)$ e $\mathrm{l}(\lambda)$ o termo que não depende do parâmetro. $\mathrm{LR}(\lambda)$ e $\mathrm{D}(\lambda)$ não se alteram pois os termos se cancelam em seu cálculo.

```{lemma, RedPoisson}
**Redefinição da função com diferentes representações da verossimilhança - Distribuição de Poisson.**
```

```{r}
veroPois <- function(par, amostra, tipo="logL", maxlogL){
   tipo = match.arg(tipo, choices=c("L","LR","logL","dev"))
   ll <- with(amostra, -n*par + soma * log(par))  
   return(switch(tipo, "L" = exp(ll),
                       "LR" = exp(ll-maxlogL),
                       "logL" = ll,
                       "dev" = 2*(maxlogL-ll)))} 
```

Comandos equivalentes aos anteriores para obtenção do gráfico são como a seguir.

```{r, eval = FALSE}
am <- list(n=length(y), soma=sum(y))
emv <- mean(y)
mll <- veroPois(emv, amostra=am, tipo="logL")
curve(veroPois(x, amostra=am, tipo="dev", maxlogL=mll), 8, 11, 
      ylab=expression(D(lambda)), xlab=expression(lambda))
```

Para ilustrar a obtenção da estimativa do parâmetro por métodos numéricos vamos  
considerar as seguintes opções:

  1. solução da equação de estimação (função escore) $\mathrm{U}(\lambda=0)$ por um método sem uso de gradientes (Brent) e por um método com uso de gradientes (Newton-Raphson);
  2. maximização direta da função de log-verossimilhança usando maximizadores numéricos.

Começamos escrevendo uma função para avaliar a função escore.

```{lemma, fcescore}
**Função escore - Distribuição de Poisson.**
```

```{r}
UPois <- function(lambda, amostra){
  return(with(amostra, n - soma/lambda))
}
```

Para obter a estimativa utilizamos inicialmente a função `uniroot()` que implementa o método de Brent para encontrar a raiz de uma equação não linear. Note que para usar este algoritmo precisamos definir um intervalo de busca através do argumento `interval.` Neste caso, especificamos o intervalo entre o menor e o maior valor observado na amostra.

```{r}
uniroot(UPois, interval = range(y), amostra = am)$root
```

Um dos algoritmos mais utilizado para encontrar a raiz de uma equação não-linear é o de Newton-Raphson que, utilizando uma expansão em séries de Taylor de $\mathrm{U}(\lambda)$,
resolve a equação a seguir até que algum critério de convergência seja atingido.
\[ \lambda^{r+1} = \lambda^{r} + \frac{\mathrm{U}(\lambda)}{\mathrm{H}(\lambda)}.\]
Para implementar o algorítmo precisamos definir primeiro a função
$\mathrm{H}(\lambda) = \mathrm{U}^{\prime}(\lambda)$.

```{lemma, dd}
**Segunda derivada da log-verossimilhança - Distribuição de Poisson.**
```

```{r}
HPois <- function(lambda, amostra){
  return(-amostra$soma/lambda^2)
}
```

Uma variante do método é utilizar $\mathrm{H}(\lambda) = -\mathrm{I_E}(\lambda)$, conhecido como _Fisher scoring_ onde $\mathrm{I_E}(\lambda) = \mathrm{E}(\mathrm{H}(\lambda))$, conhecida como matriz de informação de Fisher. 
A estimativa é obtida por este algoritmo a partir de um valor inicial, conforme implementado o exemplo abaixo. 

```{r}
maxit <- 100; lambdaNR <- 5; iter <- 0; d <- 1
while(d > 1e-12 & iter <= maxit){
    lambdaNR.new <- lambdaNR + UPois(lambdaNR, am)/HPois(lambdaNR, am)
    d <- abs(lambdaNR - lambdaNR.new)
    lambdaNR <- lambdaNR.new ; iter <- iter + 1
}
c(lambdaNR, iter)
```

No exemplo a estimativa `lambdaNR` foi obtida em `r iter` iterações.
Os comandos acima podem ser encapsulados em uma função para facilitar o uso.
Existem ainda funções no **R** que implementam este algoritmo.
Uma possível generalização é utilizar funções $\mathrm{U}(\lambda)$ e $\mathrm{H}(\lambda)$ obtidas numericamente para modelos em que não há 
expressões fechadas para estas funções.
Isto nos remete a métodos numéricos para maximização de $\mathrm{l}(\lambda)$.
Para o caso de um único paramêtro utilizamos a função `optimize()`
que utiliza o algoritmo de Brent e diversas outras funções são disponíveis
no **R** e pacotes, sendo mais comum o uso da função `optim()`. Abaixo ilustramos o uso da função `optimize()` para maximizar a log-verossimilhança.

```{r}
unlist(optimize(veroPois, int=range(y), maximum=TRUE, amostra=am)[1:2])
```

Obviamente, ambas abordagens levam a obtenção do mesmo valor para a estimativa de máxima verossimilhança.

## Intervalos de confiança

```{definition}
**Intervalo de confiança** - Um intervalo de verossimilhança para $\theta$ 
  é um intervalo da forma $\theta: \mathrm{L}(\theta|\mathbf{y}) \ge r \mathrm{L}(\hat{\theta}|\mathbf{y})$ ou equivalentemente, $\theta: \mathrm{D}(\theta) \leq c^*$, com $\mathrm{D}(\theta) = -2[\mathrm{l}(\theta)-\mathrm{l}(\hat{\theta})]$ e $c^* = - 2 \log(r)$.

```

Esta definição é bastante geral para o caso uniparamétrico, para o caso multiparâmetros 
os princípios se mantêm e trocamos o intervalo de confiança por uma região de confiança, o que será abordado mais adiante. Nesta definição o valor de $r$ precisa ser especificado entre $0$ e $1$, para intervalos não vazios, logo $c^* > 0$. Quanto maior o valor de $c^*$ mais largo será o intervalo, algumas vezes o intervalo pode ser a união de sub-intervalos disjuntos, porém este caso não é usual. Apesar do valor de $c^*$ ser necessário para a construção dos intervalos ainda não temos elementos suficientes para especificá-lo.

Usando esta definição pode-se pensar ao menos duas formas de construção de intervalos de confiança. A primeira é considerar a quantidade $\frac{\mathrm{L}(\theta)}{\mathrm{L}(\hat{\theta})} \ge r$ que é a **verossimilhança relativa**, ou seja, compara cada valor de $\theta$ com o máximo. Nestas condições a verossimilhança relativa toma sempre valores entre $0$ e $1$ e o intervalo é a região do espaço paramétrico para qual os valores associados de verossimilhança sejam uma fração não menor que $r$ do máximo valor. Por exemplo, definindo $r = 0.8$ estamos deixando que faça parte do intervalo de confiança valores que tenham até $80\%$ de compatibilidade com a amostra observada, da mesma forma poderíamos definir $r = 0.20$ ou $0.50$, dependendo de nosso critério. \cite{royall97} propõe que este valor seja definido por analogias com resultados considerados aceitáveis em experimentos simples como lançamento de uma moeda. 
Porém, em grande parte dos problemas práticos uma interpretação probabilística baseada em idéias frequentistas é usada. Voltaremos a a escolha do ponto de corte mais adiante.
Uma forma equivalente é utilizar a função _deviance_ definindo o intervalo 
pelos valores que satisfazem $\mathrm{D}(\theta) = -2[\mathrm{l}(\theta)-\mathrm{l}(\hat{\theta})] \leq -2 \log(r)$.
Esta é uma outra forma de considerar a verossimilhança relativa, 
agora em termos de diferença em log-verossimilhança. 
Neste caso a região de confiança pode ser definida como anteriormente ou valendo-se 
de propriedades frequentistas desta quantidade conforme veremos na sequência.

Em ambas abordagens surge o problema de que após definir o valor $c^* = -2\log(r)$, é necessário encontrar as raízes da função de verossimilhança relativa ou da _deviance_ que fornecem os limites do intervalo de confiança para um $c^*$ especificado. Em geral vamos chamar o valor $c^*$ ou equivalentemente $r$ de ponto de corte.
Encontrar as raízes da função comumente envolve métodos numéricos, uma vez que na maioria das situações práticas não é possível obter expressões fechadas para os limites do intervalo. 

Dado esta restrição é comum fazer uma expansão em séries de Taylor para a $\mathrm{l}(\theta)$ em torno de $\hat{\theta}$ de forma a facilitar a obtenção do intervalo de confiança. Expandindo $\mathrm{l}(\theta)$ em série de Taylor até segunda ordem em torno de $\hat{\theta}$, resulta na seguinte equação,
\[
\mathrm{D}(\theta) = -2[\mathrm{l}(\theta)-\mathrm{l}(\hat{\theta})] = 2 \left\{\mathrm{l}(\hat{\theta}) - [ \mathrm{l}(\hat{\theta}) + (\theta - \hat{\theta})\mathrm{l}^{\prime}(\hat{\theta}) + \frac{1}{2}(\theta - \hat{\theta})^2 \mathrm{l}^{\prime \prime}(\hat{\theta})] \right\} .
\]
Como por definição do EMV $\mathrm{l}^{\prime}(\hat{\theta}) = 0$, eliminando termos 
a aproximação em série de Taylor, toma a seguinte forma quadrática e define a região  
\[ \mathrm{D}(\theta) =  - (\theta - \hat{\theta})^2 \mathrm{l}^{\prime \prime}(\hat{\theta}) \leq c^*. \]
que por sua vez, define intervalos de confiança da forma,
\[ \hat{\theta} \pm \sqrt{ \frac{c^*}{-\mathrm{l}^{\prime \prime}(\hat{\theta})}}. \]

Isto corresponde a fazer uma aproximação quadrática da função _deviance_, 
que torna o intervalo fácil de ser obtido. Estendendo para o caso de multiparâmetros, tem-se que uma região de confiança para $\boldsymbol{\theta}$ é dada pelo conjunto 
${ \boldsymbol{\theta} \in \Theta : \mathrm{D}(\boldsymbol{\theta}) \leq c^*}$. 
Portanto, as duas formas de interpretar o intervalo de confiança discutidas no caso  
uniparamétrico podem ser estendidas para o caso multiparamétrico, sem problemas. 
Novamente a questão que surge é a definição de um valor para $c^*$. 
Pela abordagem frequentista é desejável que o intervalo tenha uma interpretação em termos de probabilidades ou frequência e isto é atingido através das propriedades assintóticas dos estimadores de máxima verossimilhança, que serão apresentadas na próxima Seção.

## Propriedades do EMV

Apesar de definirmos a função de verossimilhança como uma quantidade fixa avaliada em $\mathbf{y}$, devemos lembrar que ela é baseada em apenas uma realização do vetor aleatório $\mathbf{Y}$, sendo assim, estudar o comportamento probabilístico dos estimadores de máxima verossimilhança é de fundamental importância para definir suas propriedades probabilística e baseado nisto obter intervalos de confiança e testes de hipóteses. Para isto, vamos precisar de mais algumas definições.

```{definition}
**Função escore** - Sendo $\mathrm{l}(\boldsymbol{\theta}|\mathbf{y})$ a função de log-verossimilhança, o vetor _escore_ é definido por
\[ \mathrm{U}(\boldsymbol{\theta}) = \left( \frac{\partial \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_1}, \ldots, \frac{\partial \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_p}\right)^\top. \]

```

Note que a função escore nada mais é que o vetor gradiente da função de log-verossimilhança.
Definimos as matrizes de informação **observada** e **esperada**, também chamada de matriz de informação de Fisher.

```{definition}
**Matriz de informação observada** - Sendo $\mathrm{l}(\boldsymbol{\theta}|\mathbf{y})$ a função de log-verossimilhança, a matriz de informação observada é definida por
\[ \mathrm{I}_O(\boldsymbol{\theta}) = \left[\begin{array}{cccc}
 - \frac{\partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_1^2}  & \ldots  &  \ldots & -\frac{\partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_1 \partial \theta_p}  \\
                \vdots                                           & \ddots    & - \frac{\partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_i \partial \theta_j}& \vdots \\
                \vdots                                           & - \frac{\partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_j \partial \theta_i} & \ddots & \vdots \\
- \frac{\partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_p \partial \theta_1} & \ldots & \ldots & - \frac{ \partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_p^2} 
\end{array}\right]. \]

```

```{definition}
**Matriz de informação esperada** - Sendo $\mathrm{l}(\boldsymbol{\theta}|\mathbf{y})$ a função de log-verossimilhança, a matriz de informação esperada é definida por

\[ \mathrm{I}_E(\boldsymbol{\theta}) = \left[\begin{array}{cccc}
 \mathrm{E} \left[- \frac{\partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_1^2} \right]  & \ldots  &  \ldots & \mathrm{E} \left[-\frac{\partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_1 \partial \theta_p}\right]  \\
                \vdots                                           & \ddots    & \mathrm{E} \left[- \frac{\partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_i \partial \theta_j} \right]& \vdots \\
                \vdots                                           & \mathrm{E} \left[ - \frac{\partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_j \partial \theta_i}\right] & \ddots & \vdots \\
\mathrm{E} \left[- \frac{\partial^2 \mathrm{l}(\boldsymbol{\theta})}{\partial \theta_p \partial \theta_1}\right] & \ldots & \ldots & \mathrm{E} \left[- \frac{ \partial^2 \mathrm{l}(\underline{\theta})}{\partial \theta_p^2}\right] 
\end{array}\right]. \]

```

Duas propriedades importantes da função escore são apresentadas nos Teoremas a seguir.

```{theorem, label="bartlet1"}
**Primeira igualdade de Bartlett** - Sendo $\mathrm{U}(\boldsymbol{\theta})$ a função escore, então
$$\mathrm{E}(\mathrm{U}(\boldsymbol{\theta})) = 0.$$
```

```{theorem, label="bartlet2"}
**Segunda igualdade de Bartlett** - Sendo $\mathrm{U}(\boldsymbol{\theta})$ a função escore, então
$$\mathrm{V}(\mathrm{U}(\boldsymbol{\theta})) = \mathrm{E}(\mathrm{I}_O(\boldsymbol{\theta})) = \mathrm{I}_E(\boldsymbol{\theta}).$$
```

Note que a variância do vetor $\mathrm{U}(\boldsymbol{\theta})$ é a matriz com entradas
\[ \left[\begin{array}{cccc}
 \mathrm{Cov}(\mathrm{U_1}, \mathrm{U_1})  & \ldots  &  \ldots & \mathrm{Cov}(\mathrm{U_1},\mathrm{U_d})  \\
  \vdots        & \ddots  &  \mathrm{Cov}(\mathrm{U_i}, \mathrm{U_j}) & \vdots \\
  \vdots        & \mathrm{Cov}(\mathrm{U_j}, \mathrm{U_i}) & \ddots & \vdots \\
\mathrm{Cov}(\mathrm{U_d},\mathrm{U_1}) & \ldots & \ldots & \mathrm{Cov}(\mathrm{U_d}, \mathrm{U_d}) 
\end{array}\right]. \]
onde $\mathrm{Cov}(\mathrm{U_i}, \mathrm{U_i}) = \mathrm{V}(\mathrm{U_i})$. Uma propriedade importante de $\mathrm{I}_O(\boldsymbol{\hat{\theta}})$ e $\mathrm{I}_E(\boldsymbol{\hat{\theta}})$ é que elas são matrizes definida positiva, as quais mensuram a curvatura observada/esperada da superfície de log-verossimilhança. Com estas definições, pode-se escrever a função _deviance_ aproximada para um vetor de parâmetros da seguinte forma:
\[ \mathrm{D}(\boldsymbol{\theta}) \approx (\boldsymbol{\theta} - \boldsymbol{\hat{\theta}})^\top \mathrm{I_O}(\boldsymbol{\hat{\theta}})(\boldsymbol{\theta} - \boldsymbol{\hat{\theta}}) . \]
Assim $\mathrm{D}(\boldsymbol{\theta})$ é não negativa uma vez que $\mathrm{I_O}(\boldsymbol{\hat{\theta}})$ é uma matriz positiva definida. 
Uma vez definidas as quantidades envolvidas, estamos aptos a enunciar o teorema a seguir.

```{theorem, label="DEMV"}
**Distribuição assintótica do EMV** - Para um problema de estimação regular, no limite com $n \to \infty$, se $\boldsymbol{\theta}$ é o verdadeiro vetor de parâmetros, então 
\[\hat{\boldsymbol{\theta}} \sim NM_p(\boldsymbol{\theta}, \mathrm{I_E}(\boldsymbol{\theta})^{-1}),\]
ou seja, a distribuição assintótica de $\hat{\boldsymbol{\theta}}$ é uma normal multivariada com matriz de variância/covariância dada pela inversa da matriz de informação esperada.

```

```{corollary, label="RESEMV"}
Qualquer termo assintóticamente equivalente a $\mathrm{I_E}(\boldsymbol{\theta})$ pode ser usado no Teorema \@ref(thm:DEMV). Assim, 
\[ \hat{\boldsymbol{\theta}} \sim NM_p(\boldsymbol{\theta}, \mathrm{I_E}^{-1}(\boldsymbol{\hat{\theta}}))\]
\[ \hat{\boldsymbol{\theta}} \sim NM_p(\boldsymbol{\theta}, \mathrm{I_O}^{-1}(\boldsymbol{\theta}))\]
\[ \hat{\boldsymbol{\theta}} \sim NM_p(\boldsymbol{\theta}, \mathrm{I_O}^{-1}(\boldsymbol{\hat{\theta}})).\]

```

```{theorem, label="ASS"}
**Distribuição assintótica da deviance** - Para um problema de estimação regular, no limite com $n \to \infty$, se $\boldsymbol{\theta}$ é o verdadeiro valor do parâmetro, então 
$$ \mathrm{D}(\boldsymbol{\theta}) = -2[\mathrm{l}(\boldsymbol{\theta})-\mathrm{l}(\hat{\boldsymbol{\theta}})] \sim \chi^2_d $$
ou seja, a função deviance segue uma distribuição qui-Quadrado com $p$ graus de liberdade, onde $p$ é a dimensão do vetor $\boldsymbol{\theta}$.

```

De acordo com os teoremas apresentados, podemos chegar a algumas das principais propriedades dos estimadores de máxima verossimilhança:

- O estimador de máxima verossimilhança $\hat{\boldsymbol{\theta}}$ de $\boldsymbol{\theta}$ é assintóticamente não-viciado, isto é, $\mathrm{E}(\hat{\boldsymbol{\theta}}) \to \boldsymbol{\theta}$.
- Assintóticamente $\mathrm{V}(\hat{\boldsymbol{\theta}}) \to \mathrm{I_E}^{-1}(\boldsymbol{\theta})$, o qual por uma versão multivariada do limite de Cramér-Rao é o melhor possível, mostrando que o EMV é eficiente para o vetor $\boldsymbol{\theta}$, ao menos para grandes amostras.
- Denote $\mathrm{J} = \mathrm{I_E}^{-1}(\boldsymbol{\theta})$, então $\mathrm{V}(\hat{\boldsymbol{\theta}}) = \mathrm{J}$, sendo que, $\mathrm{J}$ é uma matriz simétrica e definida positiva, com elementos $\mathrm{J_{i,j}} = \mathrm{Cov}(\hat{\boldsymbol{\theta}}_i, \hat{\boldsymbol{\theta}}_j)$ então $\mathrm{J_{i,i}}$ é a variância de $\hat{\boldsymbol{\theta}}_i$. 
Denota-se $\mathrm{J_{i,i}}^{\frac{1}{2}}$ o desvio padrão de $\hat{\boldsymbol{\theta}}_i$.
- Podemos construir intervalos de $100(1-\alpha)\%$ de confiança para $\theta_i$ na forma $\hat{\theta}_i \pm z_{\frac{\alpha}{2}} \mathrm{J_{i,i}}^{\frac{1}{2}}$. Intervalos desta forma serão denominados, intervalos de Wald ou baseados em aproximação quadrática da verossimilhança. Importante notar que estes intervalos coincidem com os obtidos baseado em aproximação por Série de Taylor de segunda ordem da função _deviance_.
- Para regiões de confiança baseados na _deviance_ considera-se $[ \boldsymbol{\theta} \in \Theta : \mathrm{D}(\boldsymbol{\theta}) \leq c^*] $, para algum valor $c^*$ a ser especificado. Pode-se escolher $c^*$ baseado em justificativas assintóticas de que $\mathrm{D}(\boldsymbol{\theta}) \sim \chi^2_p$ é uma escolha razoável para $c^* = c_{\alpha}$ com $\mathrm{P}(\chi^2_d \ge c_{\alpha}) = \alpha$, por exemplo se $\alpha = 0.05$, então $c_{\alpha} = 3.84$. Isto gera uma região de $100(1 - \alpha)\%$ de confiança. Estes intervalos serão denominados de intervalos _deviance_.

De acordo com as propriedades apresentadas tem-se duas formas básicas de construir intervalos de confiança. A primeira mais simples é baseada na aproximação quadrática da log-verossimilhança e a segunda utilizando diretamente a função _deviance_ obtida com os dados. A segunda opção é em geral mais trabalhosa computacionalmente, uma vez que usualmente gera uma equação não linear que precisa ser resolvida numericamente. 
A primeira opção é bastante direta, uma vez obtida a matriz de segundas derivadas basta invertê-la e tirar a raiz dos termos da diagonal para se obter o intervalo de confiança para cada parâmetro, marginalmente. Esta abordagem é muito simples mas apresenta limitações. Restrições naturais no espaço paramétrico como, por exemplo, 
para parâmetros de variância e correlação não são respeitadas e podem resultar em limites absurdos, com limite(s) do intervalo fora do espaço paramétrico. Os intervalos serão sempre simétricos ao aproximar a verossimilhança por uma forma quadrática, o que normalmente não produz resultados adequados para parâmetros de variância e correlação. 
Em modelos com efeitos aleatórios há um interesse natural nos parâmetros de variância, precisão e correlação. Testar a significância de tais efeitos utilizando as variâncias associadas às estimativas que indexam o modelo podem produzir resultados imprecisos. 
Logo, esta abordagem é limitida em classes mais gerais de modelos estatísticos.

A segunda opção resulta em uma região conjunta para o caso de dois ou mais parâmetros,
enquanto que pela aproximação é possível obter um intervalo marginal para cada parâmetro, 
porém baseado em uma aproximação quadrática da superfície de log-verossimilhança. 
Este tipo de representação é a mais desejável para inferência, 
porém não pode ser obtida diretamente apenas com o Teorema~\@ref(thm:ASS). 
Por exemplo, suponha que tem-se interesse em um determinado componente do vetor de parâmetros, digamos $\theta_i$. A partir da aproximação quadrática podemos facilmente construir um intervalo de confiança, tendo como $\hat{\theta}_I$ e $\hat{\theta}_S$ o seu limite inferior e superior, respectivamente. Pelo Teorema~\@ref(thm:ASS) para o caso em que a dimensão de $\boldsymbol{\theta}$ é maior que um, não temos um intervalo desta forma mas sim uma região, o que apesar de mais informativa tem menor apelo prático e apresenta dificuldades de interpretação. Uma forma intuitiva de obter um intervalo da forma $\hat{\theta}_I$ e $\hat{\theta}_S$ é fixar o restante do vetor de parâmetros nas suas estimativas de máxima verossimilhança e obter os limites em uma direção de cada vez. 
Esta abordagem tem uma clara restrição que é não levar em consideração a incerteza associada ao restante do vetor de parâmetros para a construção do intervalo.

Temos um método simples via aproximação quadrática, porém que não funciona bem quando a superfície de log-verossimilhança é assimétrica. Por outro lado, o método baseado na função _deviance_ não apresenta esta restrição mas fornece regiões de confiança conjuntas, e não diretamente limites $\hat{\theta}_I$ e $\hat{\theta}_S$ para cada parâmetro. 
Duas abordagens básicas para este problema podem ser consideradas: a primeira é fazer uma reparametrização do modelo nos parâmetros que apresentam forte assimetria ou são restritos, para torná-los irrestritos e aproximadamente simétricos, obter a variância baseada na aproximação quadrática nesta reparametrização e depois converter para a escala original. Quando este procedimento é satisfatório o custo computacional é baixo.

Para formalizar esta situação, considere o problema de obter a estimativa pontual e intervalar para um parâmetro de interesse $\phi = \mathrm{g}(\boldsymbol{\theta})$, onde $\mathrm{g}(\cdot)$ é uma função e, desde que $\mathrm{L}(\phi) = \mathrm{L}( \mathrm{g}(\boldsymbol{\theta}))$, a função de verossimilhança para $\phi$ é obtida da função de verossimilhança de $\boldsymbol{\theta}$ por uma transformação de escala. Consequentemente, como $\hat{\phi} = \mathrm{g}(\boldsymbol{\hat{\theta}})$, quando o intervalo de confiança digamos $\hat{\theta}_I$ e $\hat{\theta}_S$ for obtido diretamente pela função de verossimilhança, log-verossimilhança ou _deviance_, o intervalo para $\phi$ pode ser obtido simplesmente transformando os limites obtidos para $\theta$, no caso unidimensional. Esta propriedade é conhecida como **invariância** do estimador de máxima verossimilhança. Porém, quando o intervalo for obtido pela aproximação quadrática isso não é válido e um Teorema adicional é necessário para esta transformação.

```{theorem, label="delta"}
Considere obter um intervalo de confiança para $\phi = \mathrm{g}(\boldsymbol{\theta})$ por invariância temos que $\hat{\phi} = \mathrm{g}(\hat{\boldsymbol{\theta}})$ e a variância de $\hat{\phi}$ é dada por
\[ \mathrm{V}(\hat{\phi}) = \mathrm{V}( \mathrm{g}(\hat{\boldsymbol{\theta}})) = \nabla \mathrm{g}(\hat{\boldsymbol{\theta}})^\top \mathrm{I_E}(\hat{\boldsymbol{\theta}})^{-1}  \nabla \mathrm{g}(\hat{\boldsymbol{\theta}}) \]
com 
\[ \nabla \mathrm{g}(\hat{\boldsymbol{\theta}}) = \left( \frac{\partial \mathrm{g}(\hat{\boldsymbol{\theta}})}{\partial \theta_1}, \ldots, \frac{\partial \mathrm{g}(\hat{\boldsymbol{\theta}})}{\partial \theta_d} \right)^\top. \]

```

A partir do Teorema \@ref(thm:delta) é imediato o seguinte resultado.

```{theorem, label="deltadis"}
Para um problema de estimação regular se $\phi = g(\underline{\theta})$ são os verdadeiros valores dos parâmetros, então quando $n \to \infty$ tem-se que
\[ \hat{\boldsymbol{\phi}} \sim NM_p(\phi, \nabla \mathrm{g}(\boldsymbol{\theta})^\top \mathrm{I_E}(\boldsymbol{\theta})^{-1}  \nabla \mathrm{g}(\boldsymbol{\theta})). \]
```

Pelo Teorema \@ref(thm:deltadis), podemos construir intervalos de confiança da mesma forma anterior, porém usando a nova matriz de variância e covariância ponderada pelo gradiente da função $\mathrm{g}(\cdot)$, e assim passar de uma reparametrização para outra torna-se uma tarefa trivial. Apesar deste procedimento ser bastante útil, nem sempre é fácil encontrar uma transformação $\mathrm{g}(\cdot)$ que torne a log-verossimilhança simétrica. A forma mais efetiva de construir intervalos de confiança para parâmetros de difícil estimação é o intervalo baseado em **perfil de verossimilhança**. 

Seja $\boldsymbol{\theta} = (\boldsymbol{\phi}^\top, \boldsymbol{\lambda}^\top)^\top$, o vetor de parâmetros particionado nos vetores $\boldsymbol{\phi}$ e $\boldsymbol{\lambda}$, vamos chamar a primeira componente de interesse e a segunda de incômodo, no sentido que desejamos intervalos ou regiões de confiança para $\boldsymbol{\phi}$, que pode ser apenas um escalar. Seja $\mathrm{L}(\boldsymbol{\phi}, \boldsymbol{\lambda})$ a verossimilhança para $\boldsymbol{\phi}$ e $\boldsymbol{\lambda}$. Denota-se $\hat{\boldsymbol{\lambda}}_{\phi}$ a estimativa de máxima verossimilhança de $\boldsymbol{\lambda}$ para dado valor de $\boldsymbol{\phi}$.

```{definition, label="perfilhada"}
**Verossimilhança perfilhada** - A verossimilhança perfilhada de $\boldsymbol{\phi}$ é definida por
\[ \mathrm{L}(\boldsymbol{\phi}) = \mathrm{L}(\boldsymbol{\phi}, \hat{\boldsymbol{\lambda}}_{\phi}) \]

```

A forma apresentada na definição \@ref(def:perfilhada) sugere um procedimento de maximização em duas etapas. A primeira consiste em obter $\hat{\boldsymbol{\lambda}}_{\phi}$ que maximiza $\mathrm{l}(\boldsymbol{\phi}, \boldsymbol{\lambda}) = \log \mathrm{L}(\boldsymbol{\phi}, \boldsymbol{\lambda})$ com respeito a $\boldsymbol{\lambda}$ supondo $\boldsymbol{\phi}$ fixo. 
A seguir maximiza-se $\mathrm{l}(\boldsymbol{\phi})$. Assim, uma região ou intervalo de confiança para $\boldsymbol{\phi}$ pode ser obtida usando que
\[ 
\mathrm{D}(\boldsymbol{\phi}) = -2[\mathrm{l}(\boldsymbol{\phi})-\mathrm{l}(\hat{\boldsymbol{\phi}})] \sim \chi^2_d
\]
onde $d$ é a dimensão de $\boldsymbol{\phi}$. Note que esta forma de construção não usa a aproximação em séries de Taylor e portanto pode resultar em intervalos assimétricos. Porém, é cara computacionalmente, uma vez que precisamos resolver numéricamente uma equação não-linear que para cada avaliação necessita de um algoritmo numérico de maximização.

## Testes de hipóteses

Nesta seção mostramos como diversos testes de hipóteses surgem naturamente a partir da interpretação da função de verossimilhança.

```{definition}
**Hipótese estatística** - Chamamos de hipótese estatística qualquer afirmação acerca da distribuição de probabilidade de uma ou mais variáveis aleatórias.
```

```{definition}
**Teste de hipótese** - Chamamos de teste de uma hipótese estatística a função de decisão $\chi \to \{a_0, a_1\}$, em que $a_0$ corresponde à ação de considerar a hipótese $\mathrm{H_0}$, como verdadeira e $a_1$ corresponde à ação de considerar a hipótese $\mathrm{H_1}$ como verdadeira.
```

Na definição acima, $\chi$ denota o espaço amostral associado à amostra $y_1, y_2, \ldots, y_n$. A função de decisão $d$ divide o espaço amostral $\chi$ em dois conjuntos,
$$ A_0 = \{ ( y_1, \ldots, y_n \in \chi; d(y_1, \ldots, y_n) = a_0 \}$$
e
$$ A_1 = \{ ( y_1, \ldots, y_n \in \chi; d(y_1, \ldots, y_n) = a_1 \}$$
onde $A_0 \cup A_1 = \chi$ e $A_0 \cap A_1 = \emptyset$. Como em $A_0$ temos os pontos amostrais que levam à não rejeição de $\mathrm{H_0}$, vamos chamar de $A_0$ de região de não rejeição e, por analogia, $A_1$ de região de rejeição de $H_0$, também chamada de região crítica.

Um teste de hipótese pode resultar em um de dois tipos de erros. Tradicionalmente, esses dois tipos de erros recebem os nomes de erro Tipo I ($\alpha$) e erro Tipo II ($\beta$). 
O erro tipo I ocorre quando rejeitamos $\mathrm{H_0}$ e esta é verdadeira. O erro Tipo II ocorre quando não rejeitamos $\mathrm{H_0}$ e esta é falsa. Em termos de probabilidade temos,
$$ \alpha = \mathrm{P}(Y \in A_1 | \theta_0) \quad \text{e} \quad \beta = \mathrm{P}(Y \in A_0 | \theta_1).$$

```{definition}
O poder do teste com região crítica $A_1$ para testar $\mathrm{H_0}: \theta = \theta_0$ contra $\mathrm{H_1}: \theta = \theta_1$ é dado por 
$$\pi(\theta_1) = \mathrm{P}(Y \in A_1 | \theta_1).$$
```

Note que $\pi(\theta_1) = 1 - \beta$, e $\beta$ é a probabilidade do erro Tipo II.

### Teste da razão de verossimilhança

```{definition}
A estatística do teste da razão de verossimilhança para testar $\mathrm{H_0}: \theta \in \Theta_0$ versus $\mathrm{H_1} : \theta \in \Theta_0^c$ é 
\[ \lambda(\mathbf{y}) = \frac{\mathrm{sup}_{\Theta_0} \mathrm{L}(\theta | \mathbf{y})} {\mathrm{sup}_{\Theta} \mathrm{L}(\theta | \mathbf{y})},\] onde $\mathrm{sup}$ denota o supreme de $\mathrm{L}(\theta | \mathbf{y})$ restrito ao conjunto $\Theta$.
O teste da razão de verossimilhança (TRV) é qualquer teste que tenha uma região de rejeição da forma ${\mathbf{y} : \lambda(\mathbf{y}) \leq r}$ onde $r$ é qualquer número que satisfaça $0 \leq r \leq 1$.
```

Para testar $\mathrm{H_0}: \theta = \theta_0$ versus $\mathrm{H_1}: \theta \neq \theta_0$, suponha $Y_1, \ldots, Y_n$ sejam iid $f(\mathbf{y}|\theta)$, $\hat{\theta}$ seja o EMV de $\theta$, e $f(\mathbf{y}|\theta)$ satisfaça as condições de regularidade. Desse modo, de acordo com $\mathrm{H_0}$, pelo Teorema \@ref(thm:ASS) à medida que $n \to \infty$
 $$ -2 \log \lambda(\underline{y}) \to \chi^2_1. $$

### Teste de Wald

Suponha que deseja-se testar a hipótese bilateral $\mathrm{H_0} : \theta = \theta_0$ versus $\mathrm{H_1} : \theta \neq \theta_0$. Um teste aproximado poderia ter como base a estatística $\mathrm{Z_n} = (\mathrm{W_n} - \theta_0)/\mathrm{S_n}$ e rejeitaria $\mathrm{H_0}$ se, e somente se, $\mathrm{Z_n} < -z_{\alpha/2}$. Se $\mathrm{H_0}$ for verdadeira, então $\theta = \theta_0$ e $Z_n$ converge em distribuição para $Z \sim N(0,1)$. Portanto, a probabilidade do Erro Tipo I, $\mathrm{P}_{\theta_0}(\mathrm{Z_n} < - z_{\alpha/2} \quad \text{ou} \quad \mathrm{Z_n} > z_{\alpha/2}) \to \mathrm{P}(Z < -z_{\alpha/2} \quad \text{ou} \quad Z > z_{\alpha/2}) = \alpha $,
este é, assintoticamente, um teste de tamanho $\alpha$. Em geral, um teste de Wald é um teste com base em uma estatística da forma,
\[ \mathrm{Z_n} = \frac{\mathrm{W_n} -  \theta_0}{\mathrm{S_n} } \]
onde $\theta_0$ é um valor hipotético do parâmetro $\theta$, $\mathrm{W_n}$ é um estimador de $\theta$ e $\mathrm{S_n}$ é o erro padrão de $\mathrm{W_n}$, uma estimativa do desvio padrão de $\mathrm{W_n}$. Se $\mathrm{W_n}$ for o EMV para $\theta$, então, $ \sqrt{\mathrm{I_O}(\hat{\theta})}$ é o erro padrão de $\mathrm{W_n}$. 

### Teste escore

A estatística de escore é definida como
$$\mathrm{U}(\theta) = \frac{\partial}{\partial \theta} \mathrm{l}(\theta | \boldsymbol{Y})$$

Sabemos que para todo $\theta$, $\mathrm{E}_{\theta} (\mathrm{U}(\theta)) = 0$. Em particular, se estivermos testando $\mathrm{H_0}: \theta = \theta_0$ e se $\mathrm{H_0}$ for verdadeira, então $\mathrm{U}(\theta)$ tem média $0$. Além disso, 
\[ \mathrm{V}_{\theta}(\mathrm{U}(\theta)) = -\mathrm{E}_{\theta} \left( \frac{\partial^2 }{\partial \theta^2} \mathrm{l}(\theta | \boldsymbol{Y}) \right) = \mathrm{I_E}(\theta)\]
ou seja, o número de informações é a variância da estatística escore. A estatística de teste para o teste de escore é 
\[ \mathrm{Z_S} = \mathrm{U}(\theta_0)/ \sqrt{\mathrm{I_E}(\theta_0)}. \]
Se $\mathrm{H_0}$ for verdadeira, $\mathrm{Z_S}$ tem média $0$ e variância $1$. 